{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web scraping\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# date parser\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# web driver\n",
    "import undetected_chromedriver as uc \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# random wait\n",
    "import time\n",
    "import random\n",
    "\n",
    "# mongodb connection\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# saving to excel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date parser function\n",
    "def parse_date(date_str):\n",
    "    date1 = datetime.strptime(date_str, '%d-%b-%Y')\n",
    "    output_date_string = date1.strftime(\"%Y-%m-%d\")\n",
    "    return output_date_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to determine ganjil genap\n",
    "def is_date(string, fuzzy=False):\n",
    "    try: \n",
    "        parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading excel file\n",
    "df = pd.read_excel('C:/Users/tobias.sion/Desktop/GIT 5 Sept 2023.xlsx') \n",
    "parse_bl = df['CNC'].tolist()\n",
    "bl_list = []\n",
    "for i in parse_bl:\n",
    "    bl_list.append(str(i))\n",
    "bl_list = [x.replace(' ', '') for x in bl_list]\n",
    "bl_list = [x for x in bl_list if x != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view bl list\n",
    "bl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting failed BL to track\n",
    "gagal = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><strong>Web Scraping Flow</strong></h3>\n",
    "<ol>\n",
    " <li>Acquiring every BL Number to track and store it into a list of BL</li>\n",
    " <li>Iterate all of the list and search it through the liners web</li>\n",
    " <li>Take list of container number and store it into a list</li>\n",
    " <li>If container number>1 iterate through all container for container's milestone info and store it into a dictionary and append that to a list of dict</li>\n",
    " <li>If container = 1 take container info and store it into a dictionary and append it to list of dictionary</li>\n",
    " <li>Modify dictionaries to match db's column template</li>\n",
    " <li>Insert list of dictionary to mongo db or export it into and excel file</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_akhir = []\n",
    "\n",
    "# web scripting\n",
    "options = Options()\n",
    "options.add_argument(\"--window-size=1920,1280\")\n",
    "driver = uc.Chrome()\n",
    "driver.get(\"https://www.cnc-line.com/ebusiness/tracking/search\")\n",
    "\n",
    "# search box\n",
    "search_box = driver.find_element(By. XPATH, '/html/body/div[2]/main/section/div/div/form[3]/fieldset/div/div[1]/span[1]/input[2]')\n",
    "search_box.send_keys(bl_list[random.randrange(0,len(bl_list))])\n",
    "\n",
    "# click search\n",
    "time.sleep(1)\n",
    "search_button = driver.find_element(By.XPATH, '/html/body/div[2]/main/section/div/div/form[3]/fieldset/div/div[2]/button')\n",
    "time.sleep(1)\n",
    "search_button.click()\n",
    "\n",
    "for q, bls in enumerate(tqdm(bl_list)):\n",
    "    try:\n",
    "        time.sleep(random.randrange(2,5))\n",
    "        # masukin BL baru\n",
    "        search_box2 = driver.find_element(By. XPATH, '/html/body/div[2]/main/section[1]/div/div/form[3]/fieldset/div/div[1]/span[1]/input[2]')\n",
    "        # driver.execute_script(\"window.scrollTo(100,document.body.scrollHeight);\")\n",
    "        search_box2.clear()\n",
    "        search_box2.send_keys(bls)\n",
    "        time.sleep(1.1)\n",
    "        search_button = driver.find_element(By.XPATH, '/html/body/div[2]/main/section[1]/div/div/form[3]/fieldset/div/div[2]/button')\n",
    "        time.sleep(1)\n",
    "        search_button.click()\n",
    "    \n",
    "        time.sleep(3)\n",
    "        # taking data from web \n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "        # finding containers in bl\n",
    "        containers_in_bl = soup.find_all('dl',{'class','container-ref'})\n",
    "        list_of_containers = []\n",
    "        for tag in containers_in_bl:\n",
    "            for e, f  in enumerate(tag.find_all('span')):\n",
    "                if len(f.text) == 11:\n",
    "                    list_of_containers.append(f.text)\n",
    "\n",
    "        # web scraping flow if bl have >1 container number\n",
    "        if len(list_of_containers)>1:\n",
    "\n",
    "            print(bls, 'consist of ', len(list_of_containers),' containers' )\n",
    "            # clicking more button\n",
    "            more_button= WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[2]/main/section[2]/div/div/ul/li[1]/article/section[2]/div[1]/div/label'))) \n",
    "            more_button.click()\n",
    "\n",
    "            time.sleep(3)\n",
    "            soup1 = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "            # finding milestone and expected data\n",
    "            data_milestone = soup1.find_all('tr',{'class','k-master-row done'}) + soup1.find_all('tr',{'class','k-alt k-master-row done'}) + soup1.find_all('tr',{'class','k-alt k-master-row current'}) + soup1.find_all('tr',{'class','k-master-row current'})\n",
    "            data_expected = soup1.find_all('tr',{'class','k-master-row inactivek-alt'}) + soup1.find_all('tr',{'class','k-master-row inactive'})\n",
    "            headline = soup1.find_all('strong')\n",
    "\n",
    "            # making a list of milestones\n",
    "            list_of_milestone_date = []\n",
    "            list_of_milestone_movement = []\n",
    "            list_of_milestone_cities = []\n",
    "            for tag in data_milestone:\n",
    "                for a, b  in enumerate(tag.find_all('span',{'class','calendar'})):\n",
    "                    list_of_milestone_date.append(b.text[-11:])\n",
    "                for c, d  in enumerate(tag.find_all('span',{'class','capsule'})):\n",
    "                    list_of_milestone_movement.append(d.text)\n",
    "                for e, f  in enumerate(tag.find_all('div',{'class','location row js-bubble'})):\n",
    "                    list_of_milestone_cities.append(f.text[:-16])\n",
    "\n",
    "            # making a list of expected dict\n",
    "            list_of_expected_date = []\n",
    "            list_of_expected_movement = []\n",
    "            list_of_expected_cities = []\n",
    "            for tag in data_expected:\n",
    "                for g, h  in enumerate(tag.find_all('span',{'class','calendar'})):\n",
    "                    list_of_expected_date.append(h.text[-11:])\n",
    "                for i, j  in enumerate(tag.find_all('span',{'class','capsule'})):\n",
    "                    list_of_expected_movement.append(j.text)\n",
    "                for k, l  in enumerate(tag.find_all('div',{'class','location row js-bubble'})):\n",
    "                    list_of_expected_cities.append(l.text[:-16])\n",
    "\n",
    "            # Apending data from list to current dict\n",
    "            current_dict = {}\n",
    "            for m, milestone in enumerate(sorted(list_of_milestone_date)):\n",
    "                if list_of_milestone_cities[m] == headline[1].text[:-5] or list_of_milestone_cities[m] == headline[2].text[:-5]:\n",
    "                    case_milestone = {list_of_milestone_movement[m] +' '+ list_of_milestone_cities[m] :list_of_milestone_date[m]}\n",
    "                    current_dict.update(case_milestone)\n",
    "\n",
    "            for e, expected in enumerate(sorted(list_of_expected_date)):\n",
    "                if list_of_expected_cities[e] == headline[2].text[:-5] or list_of_expected_cities[e] == headline[1].text[:-5]:\n",
    "                    case_expected = {\"EXPECTED \" + list_of_expected_movement[e] + ' ' +  list_of_expected_cities[e]:list_of_expected_date[e]}\n",
    "                    current_dict.update(case_expected)\n",
    "\n",
    "            # sorting dictionary using date\n",
    "            current_dict = dict(sorted(current_dict.items(), key=lambda item: parse_date(item[1])))\n",
    "\n",
    "            # cities from to\n",
    "            cities = soup1.find_all('ul',{'class','timeline--items'})\n",
    "\n",
    "            for x, container in enumerate(list_of_containers):\n",
    "                appending_dict = current_dict.copy()\n",
    "                for tag in cities:\n",
    "                    for cc, city in enumerate(tag.find_all('div',{'class':'timeline--item-description'})):\n",
    "                        case_city = {city.text.replace(\"\\n\",\"\")[:3]:city.text.replace(\"\\n\",\"\")[3:-5]}\n",
    "                        appending_dict.update(case_city)\n",
    "                appending_dict.update({\"Container Number\":container})\n",
    "                appending_dict.update({\"BL Number\":bls})\n",
    "                appending_dict.update({\"Liners\":\"CNC\"})\n",
    "\n",
    "                # appending to list of dict\n",
    "                hasil_akhir.append(appending_dict)\n",
    "                print(bls, container, \" DONE\")\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            print(bls, 'consist of 1 containers' )\n",
    "            time.sleep(1)\n",
    "            soup2 = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "            current_dict = {}\n",
    "\n",
    "            # finding milestone and expected data\n",
    "            data_milestone = soup2.find_all('tr',{'class','k-master-row done'}) + soup2.find_all('tr',{'class','k-alt k-master-row done'}) + soup2.find_all('tr',{'class','k-alt k-master-row current'}) + soup2.find_all('tr',{'class','k-master-row current'})\n",
    "            data_expected = soup2.find_all('tr',{'class','k-alt k-master-row inactive'}) + soup2.find_all('tr',{'class','k-master-row inactive'})\n",
    "            headline = soup2.find_all('strong')\n",
    "\n",
    "            # making a list of milestones\n",
    "            list_of_milestone_date = []\n",
    "            list_of_milestone_movement = []\n",
    "            list_of_milestone_cities = []\n",
    "            for tag in data_milestone:\n",
    "                for a, b  in enumerate(tag.find_all('span',{'class','calendar'})):\n",
    "                    list_of_milestone_date.append(b.text[-11:])\n",
    "                for c, d  in enumerate(tag.find_all('span',{'class','capsule'})):\n",
    "                    list_of_milestone_movement.append(d.text)\n",
    "                for e, f  in enumerate(tag.find_all('div',{'class','location row js-bubble'})):\n",
    "                    list_of_milestone_cities.append(f.text[:-16])\n",
    "\n",
    "            # making a list od expected dict\n",
    "            list_of_expected_date = []\n",
    "            list_of_expected_movement = []\n",
    "            list_of_expected_cities = []\n",
    "            for tag in data_expected:\n",
    "                for g, h  in enumerate(tag.find_all('span',{'class','calendar'})):\n",
    "                    list_of_expected_date.append(h.text[-11:])\n",
    "                for i, j  in enumerate(tag.find_all('span',{'class','capsule'})):\n",
    "                    list_of_expected_movement.append(j.text)\n",
    "                for k, l  in enumerate(tag.find_all('div',{'class','location row js-bubble'})):\n",
    "                    list_of_expected_cities.append(l.text[:-16])\n",
    "\n",
    "            # Apending data from list to current dict\n",
    "            current_dict = {}\n",
    "            for m, milestone in enumerate(sorted(list_of_milestone_date)):\n",
    "                if list_of_milestone_cities[m] == headline[2].text[:-5] or list_of_milestone_cities[m] == headline[3].text[:-5]:\n",
    "                    case_milestone = {list_of_milestone_movement[m] +' '+ list_of_milestone_cities[m] :list_of_milestone_date[m]}\n",
    "                    current_dict.update(case_milestone)\n",
    "                  \n",
    "            for e, expected in enumerate(sorted(list_of_expected_date)):\n",
    "                if list_of_expected_cities[e] == headline[3].text[:-5] or list_of_expected_cities[e] == headline[2].text[:-5]:\n",
    "                    case_expected = {\"EXPECTED \" + list_of_expected_movement[e] + ' ' +  list_of_expected_cities[e]:list_of_expected_date[e]}\n",
    "                    current_dict.update(case_expected)\n",
    "\n",
    "            # updating current dict with liners, BL number, Ctr Number, POL, POD\n",
    "            current_dict_fix = dict(sorted(current_dict.items(), key=lambda item: parse_date(item[1])))\n",
    "            current_dict_fix.update({\"Liners\":\"CNC\"})\n",
    "            current_dict_fix.update({\"BL Number\":bls})\n",
    "            current_dict_fix.update({\"Container Number\":headline[0].text})\n",
    "            current_dict_fix.update({\"POL\":headline[2].text[:-5]})\n",
    "            current_dict_fix.update({\"POD\":headline[3].text[:-5]})\n",
    "\n",
    "            # appending to list of dict\n",
    "            hasil_akhir.append(current_dict_fix)\n",
    "            print(bls, headline[0].text, \" DONE\")\n",
    "            time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        # for failed bl\n",
    "        print(e)\n",
    "        print(\"{} GAGAL!!\".format(bls))\n",
    "        gagal.append(bls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gagal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_akhir2 = []\n",
    "hasil_akhir2 = hasil_akhir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_akhir2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_akhir2.pop(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changeing city name in milestone to origin and destination refering from POL and POD\n",
    "list_of_dict_fix = []\n",
    "for fd, filter_dict in enumerate(hasil_akhir2):\n",
    "    print(filter_dict[\"Container Number\"], fd)\n",
    "    replacement_mapping = {\n",
    "        filter_dict[\"POL\"]: 'Origin',\n",
    "        filter_dict[\"POD\"]: 'Destination'\n",
    "    }\n",
    "\n",
    "    updated_dict = {}\n",
    "\n",
    "    for key, value in filter_dict.items():\n",
    "        for old_key, new_key in replacement_mapping.items():\n",
    "            try:\n",
    "                key = key.replace(old_key, new_key)\n",
    "            except:\n",
    "                pass\n",
    "        updated_dict[key] = value\n",
    "\n",
    "    list_of_dict_fix.append(updated_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dict_fix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change key to git db format\n",
    "list_of_dict_fix2 = []\n",
    "for filter_dict in list_of_dict_fix:\n",
    "    replacement_mapping = {\n",
    "        \"POL\" : \"From\",\n",
    "        \"POD\" : \"To\",\n",
    "        \"Vessel Departure Origin\": 'ATD',\n",
    "        \"Discharged Destination\": 'ATA',\n",
    "        \"EXPECTED Vessel Arrival Destination\" : \"ETD\",\n",
    "        \"Container to consignee Destination\": 'Container Release',\n",
    "        \"Empty in depot Destination\" : 'Container Return'\n",
    "    }\n",
    "\n",
    "    updated_dict = {}\n",
    "\n",
    "    for key, value in filter_dict.items():\n",
    "        for old_key, new_key in replacement_mapping.items():\n",
    "            key = key.replace(old_key, new_key)\n",
    "        updated_dict[key] = value\n",
    "\n",
    "        if is_date(value):\n",
    "            input_date = datetime.strptime(value, \"%d-%b-%Y\")\n",
    "            updated_dict[key] = input_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "    list_of_dict_fix2.append(updated_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dict_fix2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting list of dict to mongo db\n",
    "cluster = MongoClient(\"mongodb+srv://tobiassion:tobiassion@cluster0.u2vzz3d.mongodb.net/?retryWrites=true&w=majority\")\n",
    "db = cluster[\"bl_tracking\"]\n",
    "collection = db[\"all_tracking\"]\n",
    "collection.insert_many(list_of_dict_fix2)\n",
    "print(\"inserting many complete!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting to excel\n",
    "d_today = str(datetime.date.today())\n",
    "df = pd.DataFrame(list_of_dict_fix2)\n",
    "excel_file_path = 'export to excel CNC' + d_today + '.xlsx'\n",
    "df.to_excel(excel_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
